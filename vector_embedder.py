#!/usr/bin/env python3

import os
import json
import hashlib
import requests
import numpy as np
from typing import List, Dict, Any, Tuple
from dataclasses import dataclass
import torch
from transformers import AutoTokenizer, AutoModel
from dotenv import load_dotenv

load_dotenv()

@dataclass 
class MultiVectorEmbedding:
    chunk_id: str
    raw_content_vector: List[float]
    medical_summary_vector: List[float]
    entity_vector: List[float]
    question_vector: List[float]
    dense_passage_vector: List[float]
    metadata: Dict[str, Any]

class MultiVectorEmbedder:
    
    def __init__(self):
        self.api_key = os.getenv("MODELS_API_KEY")
        self.embedding_url = os.getenv("EMBEDDING_API_URL")
        
        # Initialize medical-specific model for dense passage embedding
        try:
            self.tokenizer = AutoTokenizer.from_pretrained("microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract")
            self.model = AutoModel.from_pretrained("microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract")
        except:
            print("PubMedBERT not available, using fallback")
            self.tokenizer = None
            self.model = None
    
    def create_multi_vector_embedding(self, chunk_text: str, chunk_metadata: Dict) -> MultiVectorEmbedding:
        """
        Create 5 different vector representations for a single chunk
        THIS IS THE GAME CHANGER!
        """
        
        chunk_id = chunk_metadata.get('chunk_id', hashlib.md5(chunk_text.encode()).hexdigest())
        
        # Vector 1: Raw Content Embedding
        raw_vector = self._create_raw_content_embedding(chunk_text)
        
        # Vector 2: Medical Summary Embedding
        medical_summary = self._generate_medical_summary(chunk_text)
        summary_vector = self._create_embedding(medical_summary)
        
        # Vector 3: Entity-Based Embedding
        entities = self._extract_medical_entities(chunk_text)
        entity_text = " ".join(entities)
        entity_vector = self._create_embedding(entity_text) if entity_text else raw_vector
        
        # Vector 4: Hypothetical Questions Embedding
        questions = self._generate_hypothetical_questions(chunk_text)
        questions_text = " ".join(questions)
        question_vector = self._create_embedding(questions_text) if questions_text else raw_vector
        
        # Vector 5: Dense Passage Embedding (Medical-optimized)
        dense_vector = self._create_dense_passage_embedding(chunk_text)
        
        return MultiVectorEmbedding(
            chunk_id=chunk_id,
            raw_content_vector=raw_vector,
            medical_summary_vector=summary_vector,
            entity_vector=entity_vector,
            question_vector=question_vector,
            dense_passage_vector=dense_vector,
            metadata={
                **chunk_metadata,
                "summary": medical_summary,
                "entities": entities,
                "questions": questions,
                "vector_quality_scores": self._calculate_vector_quality(
                    raw_vector, summary_vector, entity_vector, question_vector, dense_vector
                )
            }
        )
    
    def _create_raw_content_embedding(self, text: str) -> List[float]:
        """Create embedding for raw text content"""
        return self._create_embedding(text)
    
    def _create_embedding(self, text: str) -> List[float]:
        """Create embedding using custom API"""
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "input": [text],
            "model": os.getenv("EMBEDDING_MODEL_NAME", "medical-embeddings-v1"),
            "encoding_format": "float"
        }
        
        try:
            response = requests.post(
                self.embedding_url,
                headers=headers,
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                embedding = data['data'][0]['embedding']
                
                # Ensure 1024 dimensions
                if len(embedding) != 1024:
                    embedding = self._normalize_to_1024(embedding)
                
                return embedding
            else:
                # Fallback to mock embedding
                return self._create_mock_embedding(text)
        except:
            return self._create_mock_embedding(text)
    
    def _generate_medical_summary(self, text: str) -> str:
        """
        Generate clinical summary of chunk
        This captures the medical essence without noise
        """
        
        # Extract key medical information
        summary_parts = []
        
        # Look for diagnoses
        if any(word in text.lower() for word in ['diagnosis', 'diagnosed', 'impression']):
            diagnosis_sentences = [s for s in text.split('.') 
                                 if any(w in s.lower() for w in ['diagnosis', 'diagnosed'])]
            if diagnosis_sentences:
                summary_parts.append(f"Diagnosis: {diagnosis_sentences[0]}")
        
        # Look for medications
        if any(word in text.lower() for word in ['mg', 'medication', 'prescribed', 'dose']):
            med_sentences = [s for s in text.split('.') 
                           if any(w in s.lower() for w in ['mg', 'medication', 'prescribed'])]
            if med_sentences:
                summary_parts.append(f"Medications: {med_sentences[0]}")
        
        # Look for test results
        if any(word in text.lower() for word in ['showed', 'revealed', 'positive', 'negative']):
            test_sentences = [s for s in text.split('.') 
                            if any(w in s.lower() for w in ['showed', 'revealed', 'result'])]
            if test_sentences:
                summary_parts.append(f"Tests: {test_sentences[0]}")
        
        # Look for symptoms
        if any(word in text.lower() for word in ['presents', 'complains', 'symptoms', 'pain']):
            symptom_sentences = [s for s in text.split('.') 
                               if any(w in s.lower() for w in ['presents', 'complains', 'pain'])]
            if symptom_sentences:
                summary_parts.append(f"Symptoms: {symptom_sentences[0]}")
        
        if summary_parts:
            return " ".join(summary_parts)
        else:
            # Fallback: Take first two sentences
            sentences = text.split('.')[:2]
            return ". ".join(sentences)
    
    def _extract_medical_entities(self, text: str) -> List[str]:
        """Extract all medical entities from text"""
        
        entities = []
        
        # Medical conditions
        conditions = [
            'diabetes', 'hypertension', 'cancer', 'infection', 'disease',
            'syndrome', 'disorder', 'failure', 'insufficiency', 'stenosis',
            'infarction', 'hemorrhage', 'fracture', 'injury', 'trauma'
        ]
        
        for condition in conditions:
            if condition in text.lower():
                # Extract the full phrase around the condition
                import re
                pattern = rf'\b\w+\s+{condition}\b|\b{condition}\s+\w+\b'
                matches = re.findall(pattern, text, re.IGNORECASE)
                entities.extend(matches)
        
        # Medications (look for mg, ml patterns)
        med_pattern = r'\b\w+\s+\d+\s*mg\b|\b\w+\s+\d+\s*ml\b'
        medications = re.findall(med_pattern, text, re.IGNORECASE)
        entities.extend(medications)
        
        # Anatomical terms
        anatomy = [
            'heart', 'lung', 'liver', 'kidney', 'brain', 'blood',
            'artery', 'vein', 'muscle', 'bone', 'joint', 'nerve'
        ]
        
        for term in anatomy:
            if term in text.lower():
                entities.append(term)
        
        # Lab values (numeric + unit)
        lab_pattern = r'\d+\.?\d*\s*(?:mg/dL|mmol/L|ng/mL|mmHg|%|cells/Î¼L)'
        lab_values = re.findall(lab_pattern, text)
        entities.extend(lab_values)
        
        return list(set(entities))  # Remove duplicates
    
    def _generate_hypothetical_questions(self, text: str) -> List[str]:
        """
        Generate questions this chunk would answer
        REVOLUTIONARY for matching user queries!
        """
        
        questions = []
        text_lower = text.lower()
        
        # Diagnosis questions
        if 'diagnosis' in text_lower or 'diagnosed' in text_lower:
            questions.append("What is the diagnosis?")
            questions.append("What condition was diagnosed?")
        
        # Treatment questions
        if any(word in text_lower for word in ['treatment', 'prescribed', 'medication', 'mg']):
            questions.append("What treatment was prescribed?")
            questions.append("What medications are recommended?")
            questions.append("What is the dosage?")
        
        # Test result questions
        if any(word in text_lower for word in ['result', 'showed', 'revealed', 'positive', 'negative']):
            questions.append("What did the tests show?")
            questions.append("What were the test results?")
            questions.append("Are the results normal?")
        
        # Symptom questions
        if any(word in text_lower for word in ['symptom', 'presents', 'complains', 'pain']):
            questions.append("What are the symptoms?")
            questions.append("What symptoms does the patient have?")
            questions.append("What is the patient complaining of?")
        
        # Procedure questions
        if any(word in text_lower for word in ['procedure', 'surgery', 'operation', 'catheterization']):
            questions.append("What procedure was performed?")
            questions.append("What surgical intervention is needed?")
        
        # Recommendation questions
        if any(word in text_lower for word in ['recommend', 'advise', 'suggest', 'follow-up']):
            questions.append("What are the recommendations?")
            questions.append("What follow-up is needed?")
        
        # Add specific entity-based questions
        entities = self._extract_medical_entities(text)
        for entity in entities[:3]:  # Top 3 entities
            questions.append(f"What about {entity}?")
        
        return questions[:5]  # Limit to 5 questions
    
    def _create_dense_passage_embedding(self, text: str) -> List[float]:
        """
        Create medical-optimized dense passage embedding
        Using PubMedBERT or similar medical model
        """
        
        if self.tokenizer and self.model:
            try:
                # Tokenize
                inputs = self.tokenizer(
                    text,
                    padding=True,
                    truncation=True,
                    max_length=512,
                    return_tensors="pt"
                )
                
                # Get embeddings
                with torch.no_grad():
                    outputs = self.model(**inputs)
                    # Use CLS token embedding
                    embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()
                
                # Convert to list and ensure 1024 dimensions
                embedding_list = embedding.tolist()
                
                # Pad or truncate to 1024
                if len(embedding_list) < 1024:
                    embedding_list.extend([0.0] * (1024 - len(embedding_list)))
                else:
                    embedding_list = embedding_list[:1024]
                
                return embedding_list
            except:
                # Fallback to regular embedding
                return self._create_embedding(text)
        else:
            # Use regular embedding with medical prompt
            medical_prompt = f"Medical context: {text}"
            return self._create_embedding(medical_prompt)
    
    def _create_mock_embedding(self, text: str) -> List[float]:
        """Create mock embedding for testing"""
        import random
        random.seed(hashlib.md5(text.encode()).hexdigest())
        embedding = [random.random() for _ in range(1024)]
        # Normalize
        norm = sum(x**2 for x in embedding) ** 0.5
        return [x/norm for x in embedding]
    
    def _normalize_to_1024(self, embedding: List[float]) -> List[float]:
        """Normalize embedding to exactly 1024 dimensions"""
        if len(embedding) < 1024:
            # Pad with zeros
            embedding.extend([0.0] * (1024 - len(embedding)))
        else:
            # Truncate
            embedding = embedding[:1024]
        return embedding
    
    def _calculate_vector_quality(self, *vectors) -> Dict[str, float]:
        """Calculate quality scores for each vector type"""
        
        quality_scores = {}
        vector_names = ['raw', 'summary', 'entity', 'question', 'dense']
        
        for name, vector in zip(vector_names, vectors):
            # Calculate various quality metrics
            non_zero = sum(1 for v in vector if v != 0.0) / len(vector)
            variance = np.var(vector)
            norm = np.linalg.norm(vector)
            
            quality_scores[f"{name}_quality"] = {
                "non_zero_ratio": non_zero,
                "variance": float(variance),
                "norm": float(norm),
                "overall_score": (non_zero * 0.3 + min(variance, 1.0) * 0.3 + min(norm/10, 1.0) * 0.4)
            }
        
        return quality_scores


class MultiVectorIndexer:
    """Indexes multi-vector embeddings for legendary retrieval"""
    
    def __init__(self, pinecone_index):
        self.index = pinecone_index
    
    def index_multi_vector(self, multi_vector: MultiVectorEmbedding):
        """Index all 5 vectors with proper namespacing"""
        
        vectors_to_index = []
        
        # Create 5 different vector entries
        base_id = multi_vector.chunk_id
        
        # Vector 1: Raw content
        vectors_to_index.append({
            'id': f"{base_id}_raw",
            'values': multi_vector.raw_content_vector,
            'metadata': {
                **multi_vector.metadata,
                'vector_type': 'raw_content',
                'base_chunk_id': base_id
            }
        })
        
        # Vector 2: Medical summary
        vectors_to_index.append({
            'id': f"{base_id}_summary",
            'values': multi_vector.medical_summary_vector,
            'metadata': {
                **multi_vector.metadata,
                'vector_type': 'medical_summary',
                'base_chunk_id': base_id
            }
        })
        
        # Vector 3: Entities
        vectors_to_index.append({
            'id': f"{base_id}_entity",
            'values': multi_vector.entity_vector,
            'metadata': {
                **multi_vector.metadata,
                'vector_type': 'entity',
                'base_chunk_id': base_id
            }
        })
        
        # Vector 4: Questions
        vectors_to_index.append({
            'id': f"{base_id}_question",
            'values': multi_vector.question_vector,
            'metadata': {
                **multi_vector.metadata,
                'vector_type': 'question',
                'base_chunk_id': base_id
            }
        })
        
        # Vector 5: Dense passage
        vectors_to_index.append({
            'id': f"{base_id}_dense",
            'values': multi_vector.dense_passage_vector,
            'metadata': {
                **multi_vector.metadata,
                'vector_type': 'dense_passage',
                'base_chunk_id': base_id
            }
        })
        
        # Upsert all vectors
        self.index.upsert(vectors=vectors_to_index)
        
        return len(vectors_to_index)